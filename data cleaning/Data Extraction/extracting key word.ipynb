{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting Key Words**\n",
    "\n",
    "- TF-IDF (term frequency-Inverse Document Frequency): Assign importance to words based on how often they appear in the description versus a large corpus of documents.\n",
    "- Keyword Extraction Algorithms: Use Libraries like RAKE(Rapid Automatic Keyword Extraction) or TextRank to extract meaning words or phrases.\n",
    "- N-grams: Extract frequent word Combinations (eg. \"machine Learning\" instead of just \"machine\")\n",
    "- Basic Frequency-Based Approach: Counts the frequency and select the most frequency keywords.\n",
    "- Using spaCy with POS tag Filtering: it allows to filter tokend by their part-of-speech tags,which can help identify more relevant keywords (eg., nouns, adjectives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Frequency-Based Approach\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def  extracting_keywords_frequency(text, top_n=10):\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)        # Remove HTML tags\n",
    "    text = re.sub(r\"&amp;\", \"&\", text)       # Decode HTML entities\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", text) # Remove non-ASCII characters\n",
    "    text = text.replace('\\n', ' ').replace('\\t', ' ') # Remove new lines and tabs\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # Remove extra spaces\n",
    "    punctuation = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    text = text.translate(punctuation)\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_tokens = [w.lower() for w in word_tokens if not w.lower() in stop_words]\n",
    "\n",
    "    word_counts = Counter(filtered_tokens)\n",
    "    keywords= word_counts.most_common(top_n)\n",
    "    return keywords\n",
    "\n",
    "text = \"this is an example text. this text is about keyword extraction. Keyword , Keywords extraction\"\n",
    "keywords = extracting_keywords_frequency(text)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using spaCy (with POS Tag Filtering):\n",
    "\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_keywords_spacy(text, top_n=10):\n",
    "    doc = nlp(text)\n",
    "    keywords = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop and not token.is_punct and token.pos_ in (\"NOUN\", \"ADJ\"):\n",
    "            keywords.append(token.lemma_.lower())\n",
    "\n",
    "    word_counts = Counter(keywords)\n",
    "    return word_counts.most_common(top_n)\n",
    "\n",
    "text = \"This is an example text. This text is about keyword extraction. Keyword extraction is important for NLP. Natural Language Processing is a subfield of AI.\"\n",
    "keywords = extract_keywords_spacy(text)\n",
    "print(\"Keywords (spaCy with POS filtering):\", keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rake-nltk\n",
    "from rake_nltk import Rake\n",
    "\n",
    "def extract_keywords_rake(text, top_n=10):\n",
    "    r = Rake()\n",
    "    r.extract_keywords_from_text(text)\n",
    "    keywords = r.get_ranked_phrases()[:top_n]\n",
    "    return keywords\n",
    "\n",
    "text = \"This is an example text. This text is about keyword extraction. Keyword extraction is important for NLP. Natural Language Processing is a subfield of AI. This is a very complex example.\"\n",
    "keywords = extract_keywords_rake(text)\n",
    "print(\"Keywords (RAKE):\", keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def extract_keywords_tfidf(text, top_n=10):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    vectorizer.fit([text]) #tfidf needs a list\n",
    "    feature_array = vectorizer.get_feature_names_out()\n",
    "    tfidf_array = vectorizer.transform([text]).toarray()\n",
    "    df = pd.DataFrame(tfidf_array, columns=feature_array)\n",
    "    keywords = df.T.nlargest(top_n, 0)\n",
    "    return keywords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "text = \"This is an example text. This text is about keyword extraction. Keyword extraction is important for NLP. Natural Language Processing is a subfield of AI.\"\n",
    "keywords = extract_keywords_tfidf(text)\n",
    "print(\"Keywords (TF-IDF):\", keywords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
